{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac835a90",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160ccdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "209399fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import core components from ImageAtlas\n",
    "from imageatlas import (\n",
    "    ImageClusterer,\n",
    "    ClusteringResults,\n",
    "    FeaturePipeline,\n",
    "    create_feature_extractor,\n",
    "    create_reducer,\n",
    "    PCAReducer,\n",
    "    UMAPReducer,\n",
    "    create_clustering_algorithm,\n",
    "    GridVisualizer,\n",
    "    create_cluster_grids\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d287be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_DIR = \"./input_images\"\n",
    "OUTPUT_DIR = \"./output\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfb20b4",
   "metadata": {},
   "source": [
    "### High Level Workflow\n",
    "This is the main entry point. It demonstrates\n",
    "- ImageClusterer\n",
    "- ClusteringResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e51e2e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. High-Level API: ImageClusterer ---\n",
      "============================================================\n",
      "IMAGE CLUSTERING PIPELINE\n",
      "============================================================\n",
      "\n",
      "Step 1: Feature Extraction.\n",
      "Creating feature extractor: dinov2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/ahmad/.cache/torch/hub/facebookresearch_dinov2_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 662 images in ./input_images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|██████████| 166/166 [01:34<00:00,  1.75batch/s, processed=662, corrupted=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extraction completed!\n",
      "Feature Extraction Summary:\n",
      "Model: dinov2feature(vits14)\n",
      "Feature dimension: 384\n",
      "Samples processed: 662\n",
      "Extraction date: 2026-01-22T03:00:53.698923\n",
      "Device: cpu\n",
      "Batch size: 4\n",
      "Total time: 94.71279859542847\n",
      "Speed: 6.99 images/sec\n",
      "  Extracted features: (662, 384)\n",
      "\n",
      "Step 2: Dimensionality Reduction (PCA)\n",
      "Creating dimensionality reducer: pca\n",
      "   Reduced to: (662, 100)\n",
      "  Variance explained: 90.86%\n",
      "\n",
      "3. Step 3: Clustering (KMEANS)\n",
      "Creating clusterer: kmeans\n",
      "   Found 5 clusters\n",
      "   Cluster sizes: {0: 130, 3: 164, 1: 116, 4: 171, 2: 81}\n",
      "\n",
      "============================================================\n",
      "CLUSTERING COMPLETE\n",
      "============================================================\n",
      "\n",
      "Clustering results summary:    Total Images: 662\n",
      "   Number of clusters: 5\n",
      "   Cluster sizes: {0: 130, 3: 164, 1: 116, 4: 171, 2: 81}\n",
      "   Feature dimension: 384\n",
      "   Reduced dimension: 100\n",
      "   Clustering method: kmeans\n",
      "   Model: dinov2\n",
      "Clustering results summary:    Total Images: 662\n",
      "   Number of clusters: 5\n",
      "   Cluster sizes: {0: 130, 3: 164, 1: 116, 4: 171, 2: 81}\n",
      "   Feature dimension: 384\n",
      "   Reduced dimension: 100\n",
      "   Clustering method: kmeans\n",
      "   Model: dinov2\n",
      "Results exported as CSV: ./output/clustering_results.csv\n",
      "Results saved to: ./output/clustering_results.csv\n",
      "Results exported to JSON: ./output/clustering_results.json\n",
      "Results saved to: ./output/clustering_results.json\n"
     ]
    }
   ],
   "source": [
    "print(\"--- 1. High-Level API: ImageClusterer ---\")\n",
    "\n",
    "# Initialize the main Clusterer\n",
    "clusterer = ImageClusterer(\n",
    "    model='dinov2',\n",
    "    n_clusters=5,\n",
    "    clustering_method='kmeans',\n",
    "    reducer='pca',                  # Optional dimensionality reduction\n",
    "    n_components=100,\n",
    "    device='auto',\n",
    "    batch_size=4,\n",
    ")\n",
    "\n",
    "# Fit to the image directory\n",
    "# This returns a ClusteringResults object\n",
    "results = clusterer.fit(IMAGE_DIR)\n",
    "\n",
    "# Results summary\n",
    "print(results.summary())\n",
    "\n",
    "# Export the clustering results\n",
    "# To CSV\n",
    "results.to_csv(os.path.join(OUTPUT_DIR, \"clustering_results.csv\"))\n",
    "print(f\"Results saved to: {OUTPUT_DIR}/clustering_results.csv\")\n",
    "\n",
    "# To JSON\n",
    "results.to_json(os.path.join(OUTPUT_DIR, \"clustering_results.json\"))\n",
    "print(f\"Results saved to: {OUTPUT_DIR}/clustering_results.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53829a8c",
   "metadata": {},
   "source": [
    "### Feature extraction API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5029fd43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 2. Feature Extraction API ---\n",
      "Found 662 images in ./input_images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|██████████| 21/21 [01:42<00:00,  4.87s/batch, processed=662, corrupted=0]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extraction completed!\n",
      "Feature Extraction Summary:\n",
      "Model: resnet(50)\n",
      "Feature dimension: 2048\n",
      "Samples processed: 662\n",
      "Extraction date: 2026-01-22T03:08:06.484052\n",
      "Device: cpu\n",
      "Batch size: 32\n",
      "Total time: 102.31135082244873\n",
      "Speed: 6.47 images/sec\n",
      "Extracted features shape: (662, 2048)\n",
      "First filename: input_images/000106949d.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- 2. Feature Extraction API ---\")\n",
    "\n",
    "# Manually create a feature extractor\n",
    "# variants: 'vits14' (DINOV2), '50' (ResNet), 'b_16' (ViT)\n",
    "extractor = create_feature_extractor(\n",
    "    model_type='resnet',\n",
    "    variant='50',\n",
    "    device='cpu'\n",
    ")\n",
    "\n",
    "# Initialize the pipeline\n",
    "pipeline = FeaturePipeline(extractor, batch_size=32)\n",
    "\n",
    "# Extract features from the directory\n",
    "pipeline.extract_from_directory(IMAGE_DIR)\n",
    "\n",
    "# Get raw embeddings (Numpy Array)\n",
    "embeddings = pipeline.get_features()\n",
    "filenames = pipeline.get_filenames()\n",
    "\n",
    "print(f\"Extracted features shape: {embeddings.shape}\")\n",
    "print(f\"First filename: {filenames[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c156633",
   "metadata": {},
   "source": [
    "### Dimentionality Reduction API\n",
    "\n",
    "This shows how to use\n",
    "- create_reducer,\n",
    "- PCAReducer,\n",
    "- UMAPReducer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "136d486d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factory PCA output shape: (662, 50)\n",
      "Direct PCAReducer output shape: (662, 5)\n"
     ]
    }
   ],
   "source": [
    "# Method 1: Using the factory function\n",
    "reducer = create_reducer('pca', n_components=50)\n",
    "reducer_output = reducer.fit_transform(embeddings)\n",
    "print(f\"Factory PCA output shape: {reducer_output.shape}\")\n",
    "\n",
    "# Method 2: Direct class Usage (PCAReducer)\n",
    "pca = PCAReducer(n_components=5)\n",
    "reduced_pca = pca.fit_transform(embeddings)\n",
    "print(f\"Direct PCAReducer output shape: {reduced_pca.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308f7060",
   "metadata": {},
   "source": [
    "### Clustering Algorithm API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5f1ac32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 4. Clustering Algorithm API ---\n",
      "Algorithm used: KMeans\n",
      "Found clusters: 3\n",
      "Cluster sizes: {1: 139, 0: 260, 2: 263}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- 4. Clustering Algorithm API ---\")\n",
    "\n",
    "# Create a KMeans algorithm instance manually\n",
    "# This is useful if you already have embeddings and just want to cluster them\n",
    "algo = create_clustering_algorithm('kmeans', n_clusters=3)\n",
    "\n",
    "# Fit and predict\n",
    "result = algo.fit_predict(embeddings)\n",
    "\n",
    "print(f\"Algorithm used: {algo.get_algorithm_name()}\")\n",
    "print(f\"Found clusters: {result.n_clusters}\")\n",
    "print(f\"Cluster sizes: {result.get_cluster_sizes()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
